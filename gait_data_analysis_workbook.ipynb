{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d3f70d",
   "metadata": {},
   "source": [
    "# Gait Data Analysis Pipeline  \n",
    "Load gait‐parameter CSVs and reference data, merge & compare them, compute RMSE and save the data as a excel file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import scipy.stats as stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from ipywidgets import widgets, Output\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Settings ---\n",
    "trials = [f\"TEST-{chr(c)}\" for c in range(65, 77)]  # TEST-A to TEST-L\n",
    "base_path = \"/path/to/trials\"  # root folder\n",
    "output_file = os.path.join(base_path, \"gait_analysis_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa04d2b",
   "metadata": {},
   "source": [
    "## 1. Load Algorithm CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10263cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read per-trial CSVs into algo_data dict\n",
    "algo_data = {}\n",
    "for trial in trials:\n",
    "    csv_path = os.path.join(base_path, trial, \"Results\", \"Figures\", f\"{trial}_parameters.csv\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, header=[0,1])\n",
    "        # clean, re-index...\n",
    "        algo_data[trial] = df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"CSV missing for {trial}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7020c52",
   "metadata": {},
   "source": [
    "## 2. Load Reference (Awinda) Excel Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929bcddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Read per-trial Excel into ref_data dict\n",
    "ref_data = {}\n",
    "for trial in trials:\n",
    "    xls_path = os.path.join(base_path, trial, \"Awinda Summarized.xlsx\")\n",
    "    try:\n",
    "        df = pd.read_excel(xls_path, header=[1,2,3], index_col=0)\n",
    "        # clean, stack, filter mean...\n",
    "        ref_data[trial] = df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Excel missing for {trial}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ffd6fd",
   "metadata": {},
   "source": [
    "## 3. Merge Algorithm Data and Reference Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: For each trial, merge algo_data[trial] with ref_data[trial]\n",
    "merged_list = []\n",
    "for trial in trials:\n",
    "    if trial in algo_data and trial in ref_data:\n",
    "        df_a = algo_data[trial]  # reset_index, filter bilateral\n",
    "        df_r = ref_data[trial]\n",
    "        df_m = pd.merge(df_r, df_a, on=['Trial','Task','Foot'], suffixes=('_ref','_algo'))\n",
    "        merged_list.append((trial, df_a, df_r, df_m))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04300848",
   "metadata": {},
   "source": [
    "## 4. Compute RMSE Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f452b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Concatenate all merges and compute task-level RMSE\n",
    "all_merged = pd.concat([m for _,_,_,m in merged_list], ignore_index=True)\n",
    "df_bi = all_merged[all_merged['Foot']=='bilateral']\n",
    "gait_params = ['cadence','stance_time','swing_time', 'stride_length', 'stride_width']\n",
    "rmse_df = pd.DataFrame(index=df_bi['Task'].unique(), columns=gait_params)\n",
    "\n",
    "for p in gait_params:\n",
    "    x = df_bi[f\"{p}_mean_ref\"]\n",
    "    y = df_bi[f\"{p}_mean_algo\"]\n",
    "    rmse_df[p] = np.sqrt(((x-y)**2).groupby(df_bi['Task']).mean())\n",
    "rmse_df['n_trials'] = df_bi.groupby('Task').size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf74a350",
   "metadata": {},
   "source": [
    "## 5. Export to Excel Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Save each sheet into a single .xlsx\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    for trial, df_a, df_r, df_m in merged_list:\n",
    "        df_a.to_excel(writer, sheet_name=f\"{trial}_algo\")\n",
    "        df_r.to_excel(writer, sheet_name=f\"{trial}_ref\", index=False)\n",
    "        df_m.to_excel(writer, sheet_name=f\"{trial}_merged\", index=False)\n",
    "    all_merged.to_excel(writer, sheet_name=\"All_Merged\", index=False)\n",
    "    rmse_df.to_excel(writer, sheet_name=\"RMSE_Summary\")\n",
    "print(\"Workbook saved:\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49e45c",
   "metadata": {},
   "source": [
    "## 6. Visualization Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d13727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Visualization Helper Functions\n",
    "\n",
    "\n",
    "from ipywidgets import Output\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Prepare bilateral-only DataFrame\n",
    "df_bilateral = all_merged[all_merged['Foot']=='bilateral'].copy()\n",
    "\n",
    "def show_scatter(parameter, tasks=None):\n",
    "    \"\"\"\n",
    "    Scatter plot of Awinda vs. Algorithm for `parameter`.\n",
    "    Draws identity line and best-fit regression.\n",
    "    \"\"\"\n",
    "    out = Output()\n",
    "    display(out)\n",
    "    if tasks is None:\n",
    "        tasks = df_bilateral['Task'].unique().tolist()\n",
    "    dfp = df_bilateral[df_bilateral['Task'].isin(tasks)]\n",
    "    xcol = f\"{parameter}_mean_ref\"\n",
    "    ycol = f\"{parameter}_mean_algo\"\n",
    "\n",
    "    with out:\n",
    "        fig = px.scatter(\n",
    "            dfp, x=xcol, y=ycol,\n",
    "            color='Task', hover_data=['Trial']\n",
    "        )\n",
    "        # Identity line y=x\n",
    "        lims = [dfp[xcol].min(), dfp[xcol].max()]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=lims, y=lims, mode='lines',\n",
    "            line=dict(dash='dash', color='gray'),\n",
    "            name='y = x'\n",
    "        ))\n",
    "        # Best-fit regression\n",
    "        slope, intercept, r_val, _, _ = linregress(dfp[xcol], dfp[ycol])\n",
    "        fit_y = [slope * v + intercept for v in lims]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=lims, y=fit_y, mode='lines',\n",
    "            line=dict(color='blue'), name='Best fit'\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f\"Awinda vs Algo: {parameter}\",\n",
    "            xaxis_title=f\"Awinda ({parameter})\",\n",
    "            yaxis_title=f\"Algorithm ({parameter})\"\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "def show_bland_altman(parameter, tasks=None):\n",
    "    \"\"\"\n",
    "    Bland–Altman plot for `parameter`.\n",
    "    Plots mean vs bias with 95% limits of agreement.\n",
    "    \"\"\"\n",
    "    out = Output()\n",
    "    display(out)\n",
    "    if tasks is None:\n",
    "        tasks = df_bilateral['Task'].unique().tolist()\n",
    "    dfp = df_bilateral[df_bilateral['Task'].isin(tasks)]\n",
    "    xcol = f\"{parameter}_mean_ref\"\n",
    "    ycol = f\"{parameter}_mean_algo\"\n",
    "\n",
    "    mean_vals = (dfp[xcol] + dfp[ycol]) / 2\n",
    "    bias = dfp[ycol] - dfp[xcol]\n",
    "    mbias = bias.mean()\n",
    "    sd    = bias.std()\n",
    "    upper = mbias + 1.96 * sd\n",
    "    lower = mbias - 1.96 * sd\n",
    "\n",
    "    with out:\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=mean_vals, y=bias, mode='markers',\n",
    "            marker=dict(size=8), name='Data'\n",
    "        ))\n",
    "        # mean bias line\n",
    "        fig.add_hline(y=mbias, line_dash='dash', line_color='gray',\n",
    "                      annotation_text=f\"Mean bias: {mbias:.2f}\", showarrow=False)\n",
    "        # limits of agreement\n",
    "        fig.add_hline(y=upper, line_dash='dash', line_color='red',\n",
    "                      annotation_text=f\"+1.96 SD: {upper:.2f}\", showarrow=False)\n",
    "        fig.add_hline(y=lower, line_dash='dash', line_color='red',\n",
    "                      annotation_text=f\"-1.96 SD: {lower:.2f}\", showarrow=False)\n",
    "        fig.update_layout(\n",
    "            title=f\"Bland–Altman: {parameter}\",\n",
    "            xaxis_title=\"Mean of Two Systems\",\n",
    "            yaxis_title=\"Bias\"\n",
    "        )\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b800cc",
   "metadata": {},
   "source": [
    "## 7. Interactive Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Interactive Widgets Which Output a Scatter Plot and a Bland-Altman Plot\n",
    "\n",
    "# Dropdown for choosing parameter\n",
    "param_dropdown = widgets.Dropdown(\n",
    "    options=[p for p in df_bilateral.columns if p.endswith('_mean_ref')],\n",
    "    description='Parameter:',\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "\n",
    "# Multi-select for tasks\n",
    "task_selector = widgets.SelectMultiple(\n",
    "    options=df_bilateral['Task'].unique().tolist(),\n",
    "    description='Tasks:',\n",
    "    layout=widgets.Layout(width='50%', height='150px')\n",
    ")\n",
    "\n",
    "# Display controls\n",
    "display(param_dropdown, task_selector)\n",
    "\n",
    "# Update both plots when controls change\n",
    "def on_controls_change(change):\n",
    "    # clear previous outputs\n",
    "    clear_output(wait=True)\n",
    "    display(param_dropdown, task_selector)\n",
    "    # extract base param name without suffix\n",
    "    param = param_dropdown.value.rsplit('_', 2)[0]\n",
    "    show_scatter(param, list(task_selector.value))\n",
    "    show_bland_altman(param, list(task_selector.value))\n",
    "\n",
    "param_dropdown.observe(on_controls_change, names='value')\n",
    "task_selector.observe(on_controls_change, names='value')\n",
    "\n",
    "# Initial draw\n",
    "on_controls_change(None)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
