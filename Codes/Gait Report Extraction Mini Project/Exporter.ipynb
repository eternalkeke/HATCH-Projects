{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_page_1(df):\n",
    "    \n",
    "    #Step 1: Prepare the DataFrame\n",
    "    #Drop the first column containing the paragraph and renaming the second column\n",
    "    # df = df.drop(columns=[0])\n",
    "    # df.columns = ['Raw'] + list(df.columns[1:])\n",
    "    # print(df)\n",
    "    \n",
    "    #Step 2: Manually define the paramaters with units\n",
    "    parameters = [\n",
    "        \"Speed (m/s)\",\n",
    "        \"Cadence (steps/min)\",\n",
    "        \"Steps\",\n",
    "        \"Duration (s)\",\n",
    "        \"Distance (m)\"\n",
    "    ]\n",
    "    values = []\n",
    "    \n",
    "    #Step 3: Use re to extract all numeric value and store in a list in a sequential order\n",
    "    for index, row in df.iterrows():\n",
    "        text = str(row[1]).strip()\n",
    "        # print(text)\n",
    "    \n",
    "        nums = re.findall(r'\\d+\\.\\d+|\\d+', text)\n",
    "        if len(nums) > 0:\n",
    "            values.append(nums[0])\n",
    "            \n",
    "    \n",
    "    print(f\"Total number of Extracted Values: {values}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Step 4: Creates the new dataframe with 'parameters' and 'values' list\n",
    "    \n",
    "    df1 = pd.DataFrame({\n",
    "        'Parameter Name (Unit)': parameters,\n",
    "        'Value': values\n",
    "    })\n",
    "    \n",
    "    print(\"\\nPage 1 cleaning is complete\")\n",
    "    \n",
    "    return df1\n",
    "\n",
    "    \n",
    "\n",
    "def clean_page_3(df):\n",
    "    new_rows = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Ensure the row contains Step Length specifically, and that both columns have valid ± values\n",
    "        if '±' in row[1]:  \n",
    "            # Split left and right values and standard deviations\n",
    "            try:\n",
    "                left_value, left_sd = row[1].split('±')\n",
    "                if i + 1 < len(df):\n",
    "                    right_value, right_sd = row[(i + 1)][2].split('±')\n",
    "\n",
    "                    print('hello')\n",
    "                    # Append rows in a fixed order to maintain alignment\n",
    "                    new_rows.append(['Step Length (Left)', left_value.strip(), 'Value'])\n",
    "                    new_rows.append(['Step Length (Left)', left_sd.strip(), 'SD'])\n",
    "                    new_rows.append(['Step Length (Right)', right_value.strip(), 'Value'])\n",
    "                    new_rows.append(['Step Length (Right)', right_sd.strip(), 'SD'])\n",
    "                    \n",
    "            except ValueError as ve:\n",
    "                print(f\"Error in row {i}: {ve}. Skipping this row\")\n",
    "    \n",
    "    \n",
    "    # Create a new DataFrame with the aligned row\n",
    "    df3 = pd.DataFrame(new_rows, columns=['Parameter', 'Value', 'SD'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "page_cleaning_switch = {\n",
    "    1: clean_page_1,\n",
    "    3: clean_page_3\n",
    "}\n",
    "\n",
    "def get_csv_name(pdf_filename):\n",
    "    \"\"\"\n",
    "    Extracts the part of the PDF filename before the first '-' and appends '.csv'.\n",
    "    Example: 'report1-2023.pdf' -> 'report1.csv'\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(pdf_filename)\n",
    "    name_part = base_name.split('-')[0]\n",
    "    csv_name = f\"{name_part}.csv\"\n",
    "    return csv_name\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Main Extraction Function\n",
    "# -----------------------------\n",
    "\n",
    "def extract_data_from_pdfs(pdf_dir, pages, output_dir):\n",
    "    \"\"\"\n",
    "    Extracts data from specified pages in all gait reports within the given directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - pdf_dir (str): Directory containing PDF files.\n",
    "    - pages (str): Pages to extract data from (e.g., '1,2,3').\n",
    "    \n",
    "    Returns:\n",
    "    - data_frames (list): List of cleaned DataFrames from all PDFs.\n",
    "    \"\"\"\n",
    "    # Find all PDF files in the directory\n",
    "    pdf_files = glob.glob(os.path.join(pdf_dir, '*.pdf'))\n",
    "\n",
    "    if not pdf_files:\n",
    "        print(\"No PDF files found in the specified directory.\")\n",
    "        return\n",
    "\n",
    "    # Process each PDF file\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing file: {pdf_file}\")\n",
    "        \n",
    "        try:\n",
    "            # Extract tables from specified pages\n",
    "            tables = camelot.read_pdf(\n",
    "                pdf_file,\n",
    "                pages=pages,\n",
    "                flavor='stream',  # Use 'stream' or 'lattice' depending on your PDFs\n",
    "                strip_text='\\n',  # Remove line breaks within cells\n",
    "                edge_tol=500,     # Tolerance for table edge detection; adjust as needed\n",
    "                row_tol=10,       # Tolerance for row detection; adjust as needed\n",
    "            )\n",
    "\n",
    "            if tables.n == 0:\n",
    "                print(f\"    No tables found in {pdf_file} on pages {pages}.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"  Found {tables.n} tables in {pdf_file} on pages {pages}.\")\n",
    "\n",
    "            # Iterate over each extracted table\n",
    "            for i, table in enumerate(tables, start=1):\n",
    "                # print(table)\n",
    "                \n",
    "                df = table.df  # Get the table as a DataFrame\n",
    "                # print(df)\n",
    "                # Optional: Clean the DataFrame\n",
    "                df = df.dropna(how='all')           # Drop rows where all elements are NaN\n",
    "                df = df.dropna(axis=1, how='all')   # Drop columns where all elements are NaN\n",
    "\n",
    "                # Get the page number from the table\n",
    "                page_number = table.page\n",
    "\n",
    "                # Applying page-specific cleaning using the cleaning functions\n",
    "                clean_function = page_cleaning_switch.get(page_number)\n",
    "                if clean_function:\n",
    "                    df = clean_function(df)\n",
    "                else:\n",
    "                    print(f\"No cleaning function defined for page {page_number}\")\n",
    "                    continue  # Or handle as appropriate\n",
    "                \n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  An error occurred while processing {pdf_file}: {e}\")\n",
    "\n",
    "    \n",
    "\n",
    "# -----------------------------\n",
    "# 3. Example Usage\n",
    "# -----------------------------\n",
    "\n",
    "pdf_dir = r\"C:\\Users\\yangk\\OneDrive\\Documents\\HATCH\\Programming Learning\\MotionCloud Reports\"\n",
    "pages_to_extract = '3'\n",
    "output_dir = r'C:\\Users\\yangk\\OneDrive\\Documents\\HATCH\\Programming Learning\\Extracted Data from MotionCloud Report'\n",
    "\n",
    "# Call the extraction function\n",
    "extracted_data = extract_data_from_pdfs(pdf_dir, pages_to_extract, output_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
